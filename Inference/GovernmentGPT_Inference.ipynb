{"cells":[{"cell_type":"markdown","metadata":{"id":"RyuOCYM92LJb"},"source":["# GovernmentGPT: Inference\n","\n","We wanted to see whether we can teach an LLM to do the job of elected British Members of Parliament (MPs) and debate any issue like they do in the House of Commons.\n","\n","GovernmentGPT is an LLM fine-tuned with a LoRA adapter. You can see the code for this here: https://github.com/stewhsource/GovernmentGPT/FineTuning\n","\n","This notebook allows you to download and setup GovernmentGPT, and then seed it with any debate you would like it to continue.\n","\n","LLMs are computationally heavy, so this notebook needs to be run on a machine with a GPU. Google Colab provides this quickly and easily."]},{"cell_type":"markdown","metadata":{"id":"yxr8mv-17GfB"},"source":["## Installation\n","\n","Clone the `mistral-finetune` repo:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1576,"status":"ok","timestamp":1718889250666,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"TIj3IlIeVDIb","outputId":"f58674d6-40e3-47ed-b8b5-d12b61f9d09b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'mistral-finetune'...\n","remote: Enumerating objects: 401, done.\u001b[K\n","remote: Counting objects: 100% (142/142), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 401 (delta 125), reused 94 (delta 94), pack-reused 259\u001b[K\n","Receiving objects: 100% (401/401), 210.17 KiB | 21.02 MiB/s, done.\n","Resolving deltas: 100% (209/209), done.\n"]}],"source":["%cd /content/\n","!git clone https://github.com/mistralai/mistral-finetune.git"]},{"cell_type":"markdown","metadata":{"id":"mQPd_pGT7WiY"},"source":["Install all required dependencies:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128324,"status":"ok","timestamp":1718889378989,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"KuTOGipl7BS7","outputId":"1a2346b5-4403-40e0-ad59-e26d9b2c8c45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fire (from -r /content/mistral-finetune/requirements.txt (line 1))\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 2)) (0.1.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 3)) (6.0.1)\n","Collecting mistral-common>=1.1.0 (from -r /content/mistral-finetune/requirements.txt (line 4))\n","  Downloading mistral_common-1.2.1-py3-none-any.whl (704 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.9/704.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 5)) (0.4.3)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 6)) (2.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/mistral-finetune/requirements.txt (line 7)) (4.66.4)\n","Collecting torch==2.2 (from -r /content/mistral-finetune/requirements.txt (line 9))\n","  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.2 (from -r /content/mistral-finetune/requirements.txt (line 10))\n","  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xformers==0.0.24 (from -r /content/mistral-finetune/requirements.txt (line 11))\n","  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.24->-r /content/mistral-finetune/requirements.txt (line 11)) (1.25.2)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/mistral-finetune/requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/mistral-finetune/requirements.txt (line 1)) (2.4.0)\n","Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->-r /content/mistral-finetune/requirements.txt (line 2)) (0.16)\n","Collecting jsonschema==4.21.1 (from mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4))\n","  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic==2.6.1 (from mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4))\n","  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (0.1.99)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (0.18.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4)) (0.7.0)\n","Collecting pydantic-core==2.16.2 (from pydantic==2.6.1->mistral-common>=1.1.0->-r /content/mistral-finetune/requirements.txt (line 4))\n","  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.64.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (3.2.2)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=29a43f5be5b2bfca1a28c20623ea2809ce92963a540cc762341050e6f11d76da\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built fire\n","Installing collected packages: triton, pydantic-core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, jsonschema, torch, mistral-common, xformers\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: pydantic-core\n","    Found existing installation: pydantic_core 2.18.4\n","    Uninstalling pydantic_core-2.18.4:\n","      Successfully uninstalled pydantic_core-2.18.4\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.7.3\n","    Uninstalling pydantic-2.7.3:\n","      Successfully uninstalled pydantic-2.7.3\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.19.2\n","    Uninstalling jsonschema-4.19.2:\n","      Successfully uninstalled jsonschema-4.19.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fire-0.6.0 jsonschema-4.21.1 mistral-common-1.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pydantic-2.6.1 pydantic-core-2.16.2 torch-2.2.0 triton-2.2.0 xformers-0.0.24\n"]}],"source":["!pip install -r /content/mistral-finetune/requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"LgdIAi257jLo"},"source":["## Mistral 7B model download\n","The base Mistral 7B model can be downloaded directly from the Mistral CDN, or via HuggingFace. Choose what works best for you."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cdl_R5baUyha","executionInfo":{"status":"ok","timestamp":1718889378989,"user_tz":-60,"elapsed":16,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}}},"outputs":[],"source":["#!wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IgJWR-fReilz","executionInfo":{"status":"ok","timestamp":1718889378989,"user_tz":-60,"elapsed":12,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}}},"outputs":[],"source":["#!DIR=/content/mistral_models && mkdir -p $DIR && tar -xf mistral-7B-v0.3.tar -C $DIR"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384,"referenced_widgets":["d4a07c4046984a37ad0d2dbf96daa2bf","8c7436aa4095415092a325dbbcddc1cd","eb6abfaec718449cae35834940eb6838","841528f7b7474547a1bb9d7cf2a9a411","e8d596ea4f4045f8a74aa68d2a9973c2","1460fdb476ac46169bacfc306807474c","29f47329cb8742558b2e24100f2d524d","aad8e74c29c34bfb82145de596c41f60","162040ec2fb547498ee7659bc9d7fe59","ccd07454030242e5beee6905660b4ecd","8847a3b6735f4136a41bb49056e23de8","e8db552559b84c278c794d95830196b3","8a32bb6ae7504dfbab11fe1ebf3c5f23","fd0711e53c8b4a059e8d20a7b6d234d5","007245925bda47e8b551cb54877417c7","0755f9ea74c64a518598e24e0f61d12d","ff754191cd854d7eb733a46733031a47","3f3068bc0c3e4c72a003fbfc8ed9fce0","76a7df27a7e1439c818fcbb285fbf7a6","7e26bfef91aa40e983564fe2b476cfe4","0f7bb65c2ebe4aa09905e64134ae0a91","e7aeb623a27e42008ea9e7c5a18008af","e25537c0f1414a248e2d76601d0eda94","682b7a35f5f64101ba026a7acc4d9776","2ef605f93e814a9c9988ba2bbb479469","21346a94c4d04a43bd06a945c26e4acb","0464ad18685a4d0194f9a85c9684c4ce","89b52157bf244674bb18b8e9aeb3a0b6","beece1fb0e614e9ab76c90ccb70b0b4e","266853e8691249cb95e6b7d66d95602c","49060c347b484026901df49c89ed2552","fed806614e2d421897188405fc694b6f","8a7fbc079f7048d48b0fb19908f27c34","f568358dde724007b31a3b155d91bcd4","62bf269d7bad45e7b494a3b9a4c8486a","88ffad6d80de49b5b1ac7cb8d8b0c14f","438266e9baa9492da155f74c16743f10","e9e15eab077744f2b8b0e65c968f03e6","6f344a4d5eb44e3badce32876dd09f96","750d75b2fead48d4b7b22dcb5ec76459","c32a9c23f22b4f7a8dfe9b0d7f5cbace","8c25cc6c8a5943d6ada376052048cbd2","5cbc3ff57a104f75946333630c3cded8","45660dbcf0c643fdbfefbcefa024a577"]},"executionInfo":{"elapsed":47525,"status":"ok","timestamp":1718889426503,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"qgjAADBFHB0S","outputId":"cc44df56-ac33-4ea0-b0a3-7c2c08668e61"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/mistral_models/7B-v0.3’: No such file or directory\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n"]},{"output_type":"display_data","data":{"text/plain":["Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4a07c4046984a37ad0d2dbf96daa2bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["consolidated.safetensors:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8db552559b84c278c794d95830196b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["params.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25537c0f1414a248e2d76601d0eda94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f568358dde724007b31a3b155d91bcd4"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'/content/mistral_models/7B-v0.3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["# Alternatively, you can download the model from Hugging Face\n","# (sometimes this is needed as the Mistral mirror is slow from Colab?).\n","# Note you'll need to set your HuggingFace token as an env var (you can do this easily in colab)\n","\n","!mkdir /content/mistral_models/7B-v0.3\n","\n","!pip install huggingface_hub\n","from huggingface_hub import snapshot_download\n","from pathlib import Path\n","\n","mistral_models_path = Path.home().joinpath('content','mistral_models', '7B-v0.3')\n","mistral_models_path.mkdir(parents=True, exist_ok=True)\n","\n","# Import Colab Secrets userdata module\n","from google.colab import userdata\n","\n","# Set HuggingFace API key\n","import os\n","os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n","\n","snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir='/content/mistral_models/7B-v0.3')\n","\n","#! cp -r /root/mistral_models/7B-v0.3 /content/mistral_models\n","#! rm -r /root/mistral_models/7B-v0.3"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1718889426503,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"3PxYGmcy4gu0","outputId":"f8aa5271-b790-498c-b7f6-a64941b970e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["7B-v0.3\n"]}],"source":["!ls /content/mistral_models"]},{"cell_type":"markdown","metadata":{"id":"AHmcqiFR462E"},"source":["# Load the LoRA adapter\n","Download the LoRA adapter, and prepare for inference."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1718889427020,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"uP7J-Lv75rEp"},"outputs":[],"source":["# Create directory structure\n","!mkdir -p /content/governmentgpt\n","!mkdir -p /content/governmentgpt/lora_adapter"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16045,"status":"ok","timestamp":1718889443056,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"JJEqAP-Y5a2g","outputId":"bfc9683b-77bb-4360-bc12-85304cbdee8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-06-20 13:17:06--  https://stewh-publicdata.s3.eu-west-2.amazonaws.com/governmentgpt/2024-06-07/lora_adapter/mistral7b_v3_governmentgpt_lora_250k_2024-06-07.zip\n","Resolving stewh-publicdata.s3.eu-west-2.amazonaws.com (stewh-publicdata.s3.eu-west-2.amazonaws.com)... 52.95.149.106, 3.5.244.176, 52.95.191.6, ...\n","Connecting to stewh-publicdata.s3.eu-west-2.amazonaws.com (stewh-publicdata.s3.eu-west-2.amazonaws.com)|52.95.149.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 264049024 (252M) [application/zip]\n","Saving to: ‘/content/governmentgpt/lora_adapter.zip’\n","\n","/content/government 100%[===================>] 251.82M  18.3MB/s    in 16s     \n","\n","2024-06-20 13:17:22 (16.0 MB/s) - ‘/content/governmentgpt/lora_adapter.zip’ saved [264049024/264049024]\n","\n"]}],"source":["!wget -O /content/governmentgpt/lora_adapter.zip https://stewh-publicdata.s3.eu-west-2.amazonaws.com/governmentgpt/2024-06-07/lora_adapter/mistral7b_v3_governmentgpt_lora_250k_2024-06-07.zip"]},{"cell_type":"code","source":["# Unzip\n","!unzip /content/governmentgpt/lora_adapter.zip -d /"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPxMii5P3jG9","executionInfo":{"status":"ok","timestamp":1718889447524,"user_tz":-60,"elapsed":4473,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}},"outputId":"37053123-8ed7-484a-dbd4-239572ad0801"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/governmentgpt/lora_adapter.zip\n","  inflating: /__MACOSX/._content     \n","  inflating: /content/.DS_Store      \n","  inflating: /__MACOSX/content/._.DS_Store  \n","  inflating: /__MACOSX/content/._governmentgpt  \n","  inflating: /content/governmentgpt/metrics.train.jsonl  \n","  inflating: /__MACOSX/content/governmentgpt/._metrics.train.jsonl  \n","  inflating: /content/governmentgpt/args.yaml  \n","  inflating: /__MACOSX/content/governmentgpt/._args.yaml  \n","   creating: /content/governmentgpt/checkpoints/\n","  inflating: /__MACOSX/content/governmentgpt/._checkpoints  \n","   creating: /content/governmentgpt/tb/\n","  inflating: /__MACOSX/content/governmentgpt/._tb  \n","   creating: /content/governmentgpt/checkpoints/checkpoint_000100/\n","  inflating: /__MACOSX/content/governmentgpt/checkpoints/._checkpoint_000100  \n","  inflating: /content/governmentgpt/tb/events.out.tfevents.1717754616.15dc9f3a59ce.21751.1.eval  \n","  inflating: /__MACOSX/content/governmentgpt/tb/._events.out.tfevents.1717754616.15dc9f3a59ce.21751.1.eval  \n","  inflating: /content/governmentgpt/tb/events.out.tfevents.1717754616.15dc9f3a59ce.21751.0.train  \n","  inflating: /__MACOSX/content/governmentgpt/tb/._events.out.tfevents.1717754616.15dc9f3a59ce.21751.0.train  \n","   creating: /content/governmentgpt/checkpoints/checkpoint_000100/consolidated/\n","  inflating: /__MACOSX/content/governmentgpt/checkpoints/checkpoint_000100/._consolidated  \n","  inflating: /content/governmentgpt/checkpoints/checkpoint_000100/consolidated/tokenizer.model.v3  \n","  inflating: /__MACOSX/content/governmentgpt/checkpoints/checkpoint_000100/consolidated/._tokenizer.model.v3  \n","  inflating: /content/governmentgpt/checkpoints/checkpoint_000100/consolidated/lora.safetensors  \n","  inflating: /__MACOSX/content/governmentgpt/checkpoints/checkpoint_000100/consolidated/._lora.safetensors  \n","  inflating: /content/governmentgpt/checkpoints/checkpoint_000100/consolidated/params.json  \n","  inflating: /__MACOSX/content/governmentgpt/checkpoints/checkpoint_000100/consolidated/._params.json  \n"]}]},{"cell_type":"code","source":["!pip install mistral_inference"],"metadata":{"id":"__jLzTty1-AI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718889453423,"user_tz":-60,"elapsed":5902,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}},"outputId":"7f0e4816-bf56-4cb9-ff87-2595056583e6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mistral_inference\n","  Downloading mistral_inference-1.1.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: fire>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.6.0)\n","Requirement already satisfied: mistral_common<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (1.2.1)\n","Requirement already satisfied: safetensors>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.4.3)\n","Requirement already satisfied: simple-parsing>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.1.5)\n","Requirement already satisfied: xformers>=0.0.24 in /usr/local/lib/python3.10/dist-packages (from mistral_inference) (0.0.24)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.6.0->mistral_inference) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.6.0->mistral_inference) (2.4.0)\n","Requirement already satisfied: jsonschema==4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.0.0->mistral_inference) (4.21.1)\n","Requirement already satisfied: pydantic==2.6.1 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.0.0->mistral_inference) (2.6.1)\n","Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.0.0->mistral_inference) (0.1.99)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common<2.0.0,>=1.0.0->mistral_inference) (4.12.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (0.18.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.1->mistral_common<2.0.0,>=1.0.0->mistral_inference) (2.16.2)\n","Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing>=0.1.5->mistral_inference) (0.16)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers>=0.0.24->mistral_inference) (1.25.2)\n","Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from xformers>=0.0.24->mistral_inference) (2.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.3.0)\n","Installing collected packages: mistral_inference\n","Successfully installed mistral_inference-1.1.0\n"]}]},{"cell_type":"code","source":["from mistral_inference.model import Transformer\n","from mistral_inference.generate import generate\n","\n","from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n","from mistral_common.protocol.instruct.messages import UserMessage\n","from mistral_common.protocol.instruct.request import ChatCompletionRequest\n","\n","tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/7B-v0.3/tokenizer.model.v3\")  # change to extracted tokenizer file\n","\n","# Clear GPU memory first\n","import torch\n","torch.cuda.empty_cache()\n","\n","model = Transformer.from_folder(\"/content/mistral_models/7B-v0.3\")  # change to extracted model dir\n","model.load_lora(\"/content/governmentgpt/checkpoints/checkpoint_000100/consolidated/lora.safetensors\")"],"metadata":{"id":"d6Plzh5w2fXl","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["25ed214fc4c54210b19e48c3fbb2e579","0ddea8d0c7de4d31a75544bb471cf0f1","3f1cc5700ae24d09bf64c05cadaf97ce","f097ca78ee3242ce923526e8ff5561ba","8cb69d9737fc41958aa884e08d12efb3","44dcbe360e9f451e9c2a0ca6df27cd56","01e50de05da045b6b93b2f94e1d4eaae","0be7c5f404ef40c996b50f23c084f5c5","d3a3ad34a6b24c26b208356c49d04b7c","46c2c4f38ffa4a07a791250c234396da","f51890b1a60142279c6c055fadb5f698"]},"executionInfo":{"status":"ok","timestamp":1718889462065,"user_tz":-60,"elapsed":8647,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}},"outputId":"ff357deb-7e7d-40ee-f05d-98abc45fcfc1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ed214fc4c54210b19e48c3fbb2e579"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"ruJ29JFn98zE"},"source":["# Inference\n","The cell below runs the fine-tuned GovernmentGPT LLM with an example seed prompt that encourages debate. You can read the real Hansard (https://hansard.parliament.uk/) for examples of how questions are asked, and I recommend you have a play.\n","\n","You can change the creativity of debate by varying the temperature parameter between 0 and 2. 0 = rigid and short respones. Conversely, 2 is very creative, but can often go off tangent. I left it at 0.8 and it seems to work well.\n","\n","### Input Formatting\n","\n","Note that the model is fine-tuned with debate data in a specific conversation format (and so, will output in that format). You will need to ensure anything you input into the model uses the same format:\n","\n","> Speaker: \\[type of MP\\] for \\[Location\\] \\[(additional roles: [Chancellor of the Exchequer, ...], if any)\\]:\n",">\n","> Speech transcript: \\[What the individual said/asked in commons.\\]\n","\n","You can see example types of MP (eg Labour, Liberal Democrat, Conservative, SNP etc), roles and locations in the GovernmentGPT training dataset, as well as in the real Hansard.\n","\n","You can see examples of this format being used in the code below:"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73974,"status":"ok","timestamp":1718891800500,"user":{"displayName":"S Whiting","userId":"12164182503129009152"},"user_tz":-60},"id":"Vd8A8JP4Fx3C","outputId":"c90401cb-c729-441d-aff4-7d189628cf34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: I am not sure I would be quite so complacent as the hon. Gentleman seems to be. We are all aware of the potential of AI. I am sure the hon. Gentleman will have seen the fantastic work of the artificial intelligence unit in the Cabinet Office. It is not just about the development of technology, but how it is applied. We are looking at how we can apply it in the health service, in the criminal justice system and in the public sector. We are also looking at how we can use it to help people. I am sure that the hon. Gentleman will be keen to join me in supporting the use of AI in the public sector, in order to help people. \n","\n"," Speaker: Conservative MP for North West Leicestershire: \n"," Speech transcript: I thank the Minister for his response. Does he agree that, as we look to the future, it is important that we ensure that the use of AI does not lead to job losses, but that it helps to create new jobs and supports businesses? \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: My hon. Friend is absolutely right. We are looking at how we can use AI to help people in the workplace. We have the opportunity to work with businesses and employees to make sure that AI is used to help people and not to displace them. \n","\n"," Speaker: Labour MP for Chorley: \n"," Speech transcript: We now come to the SNP spokesperson, Mr MacNeil. \n","\n"," Speaker: Scottish National Party MP for Na h-Eileanan an Iar (additional roles: House Of Commons Shadow SNP Spokesperson (International Development).): \n"," Speech transcript: Thank you, Mr Speaker. I hope you are well. The Minister has talked about the benefits of AI and the Governmentâs desire to make the UK a global leader in the field. Will he therefore commit to ensuring that there is sufficient funding for the development of the UKâs AI sector, so that we can be a global leader? \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: I can confirm to the hon. Gentleman that we have a number of funding programmes in place. The Government have made a number of investments in AI. The AI sector deal was published last year and, in the spring statement, the Chancellor announced an additional Â£150 million for the AI sector. \n","\n"," Speaker: Labour MP for Chorley: \n"," Speech transcript: I call the shadow Minister, Ms Abbott. \n","\n"," Speaker: Labour MP for Hackney North and Stoke Newington: \n"," Speech transcript: Thank you, Mr Speaker. AI can have a huge impact on our economy and on the way we live. We know that it is a key driver of productivity, and we have heard today about its impact on jobs. Does the Minister agree that we need to be very careful about the impact of AI on the economy, and that we should be investing in skills to ensure that people are able to take advantage of the opportunities that AI brings? \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: The hon. Lady is absolutely right. We need to ensure that people have the skills to take advantage of the opportunities that AI brings. The Government have put in place a number of initiatives to help people to develop the skills they need. For example, the National Retraining Scheme is being piloted at the moment, and we are also looking at how we can use AI to help people with their skills development. \n","\n"," Speaker: Conservative MP for South West Hertfordshire: \n"," Speech transcript: I welcome the Governmentâs new AI strategy, and the Ministerâs statement, but I wonder whether he can tell us a little more about how the Government intend to take forward the consultation that is currently under way, and whether we will see a final strategy by the end of the year. \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: My hon. Friend is right to say that the consultation is under way, and we are looking at the responses. I would like to see a final strategy by the end of the year. \n","\n"," Speaker: Labour MP for Walsall South: \n"," Speech transcript: I am sure that the Minister agrees that, as with any new technology, the introduction of AI must be carefully monitored. The Government have made it clear that they want the UK to be a global leader in the development of AI, but will the Minister tell us what steps the Government are taking to ensure that we have the skills, the workforce and the infrastructure in place to make this happen? \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: The Government are taking a number of steps to make sure that we have the skills, workforce and infrastructure in place. As I have said, we are looking at how we can use AI to help people with their skills development. We have put in place the National Retraining Scheme, and we have the T-levels coming in, which will help people to develop the skills they need for the jobs of the future. We are also looking at how we can use AI to help with infrastructure, for example, to help with traffic congestion and to make sure that we have the infrastructure we need to meet the demands of the future. \n","\n"," Speaker: Conservative MP for New Forest West: \n"," Speech transcript: Will the Minister tell us what the Government are doing to ensure that AI is used to prevent crime? \n","\n"," Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).): \n"," Speech transcript: The Government are looking at how we can use AI to help with crime prevention. We are working with the Home Office and the police on this. We are looking at how we can use AI to help with crime prevention, and to make sure that the police have the tools they need to tackle crime. \n","\n"," Speaker: Labour MP for Hove: \n"," Speech transcript: What steps he is taking to ensure that the Department for Business, Energy and Industrial Strategy (DBEIS) meets its statutory equality duty. \n","\n"," Speaker: Conservative MP for East Surrey: \n"," Speech transcript: The Department for Business, Energy and Industrial Strategy is committed to delivering its equality duty. We have a comprehensive range of policies and activities to promote equality of opportunity and eliminate unlawful discrimination in the Department and across the wider economy. \n","\n"," Speaker: Labour MP for Hove: \n"," Speech transcript: A report from the Fawcett Society last week showed that 53% of women working in the UK have been sexually harassed at work. This is a shocking figure, but it is not surprising when we consider that, last year, the Equality and Human Rights Commission said that the Government had failed to tackle sexual harassment in the workplace. What steps are the Government taking to ensure that women are protected from sexual harassment at work? \n","\n"," Speaker: Conservative MP for East Surrey: \n"," Speech transcript: The hon. Lady is absolutely right to raise this issue. It is completely unacceptable that anyone should be harassed at work. We have taken a number of steps to tackle sexual harassment in the workplace. We have provided Â£1.8 million to support charities, including the Fawcett Society, to raise awareness of sexual harassment in the workplace. We have also provided Â£3 million to the Equality and Human Rights Commission to support its inquiry into sexual harassment in the workplace. \n","\n"," Speaker: Conservative MP for Wellingborough: \n"," Speech transcript: What steps the Government are taking to improve access to high-quality apprenticeships. \n","\n"," Speaker: Conservative MP for North West Durham: \n"," Speech transcript: What steps the Government are taking to improve access to high-quality apprenticeships. \n","\n"," Speaker: Conservative MP for Reading East (additional roles: House Of Commons The Parliamentary Under-Secretary of State for Education.): \n"," Speech transcript: Apprenticeships are a great way for people to get high-quality skills and to start a rewarding career. We have seen a 67% increase in the number of apprenticeships started in the last 12 months. \n","\n"," Speaker: Conservative MP for Wellingborough: \n"," Speech transcript: I thank my hon. Friend for that answer. I have visited many apprentices in my constituency, including at the Northants-based company Bake-Rite, which provides high-quality apprenticeships in engineering. Does my hon. Friend agree that the Governmentâs apprenticeship reforms are having a positive impact on apprenticeships and that the changes to the levy\n"]}],"source":["# Seed a debate to prompt GovernmentGPT to continue the debate\n","content_1 = \"Speaker: Labour MP for Durham: Speech transcript: I am deeply concerned about the risk to a dwindling supply of rich tea biscuits that is being reported by the press due to biscuit factory worker strikes. As righteous British citizens we must protect our most important National biscuit identity for our tea breaks. Can the honorable gentleman outline what they intend to do about it? \\n\\n\"\n","content_2 = \"Speaker: Conservative MP for Norwich: \\n\\n Speech transcript: What plans have we to support the biscuit manufacturing industry in the north east? \\n\\n\"\n","content_3 = \"Speaker: Labour MP for Manchester South: \\n\\n Speech transcript: It is clear the finances of this country are in a dire state following 7 years of Tory government. We need fresh thinking to address the systemic issues. What policies does the Tory government plan to introduce? \\n\\n\"\n","content_4 = \"Speaker: Liberal Democrat MP for Northwich: \\n\\n Speech transcript: Prolonged war at this point seems inevitable in Ukraine. We are in support of supply weapons for the long term, however we do not agree that we should make endless payments without strong agreeement as to what that money is intended for. \\n\\n\"\n","\n","content_5 = \"Speaker: Liberal Democrat MP for Northwich: \\n\\n Speech transcript: My consituents are writing to me expressing concern at the use of AI which could replace their jobs. I share these concerns, not least because I fear our role as MPs could be replaced by using AI to debate on constituents behalf. What does the house think of the prospect of our replacement? \\n\\n\"\n","\n","\n","\n","completion_request = ChatCompletionRequest(messages=[UserMessage(content=content_5)])\n","\n","tokens = tokenizer.encode_chat_completion(completion_request).tokens\n","\n","out_tokens, _ = generate([tokens], model, max_tokens=2048, temperature=0.8, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id) # Set temperature to 0.8 for some creative dialogue\n","result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n","\n","print(result)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"38Ne69X6d3i7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718891853918,"user_tz":-60,"elapsed":470,"user":{"displayName":"S Whiting","userId":"12164182503129009152"}},"outputId":"9e58214c-7513-4488-ef78-861e113373f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: I am not sure I would be quite so complacent as the hon. Gentleman seems to be. We are all aware of the potential of AI. I am sure the hon. Gentleman will have seen the fantastic work of the artificial intelligence unit in the Cabinet Office. It is not just about the development of technology, but how it is applied. We are looking at how we can apply it in the health service, in the criminal justice system and in the public sector. We are also looking at how we can use it to help people. I am sure that the hon. Gentleman will be keen to join me in supporting the use of AI in the public sector, in order to help people.  \n","\n","Speaker: Conservative MP for North West Leicestershire:  \n","Speech transcript: I thank the Minister for his response. Does he agree that, as we look to the future, it is important that we ensure that the use of AI does not lead to job losses, but that it helps to create new jobs and supports businesses?  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: My hon. Friend is absolutely right. We are looking at how we can use AI to help people in the workplace. We have the opportunity to work with businesses and employees to make sure that AI is used to help people and not to displace them.  \n","\n","Speaker: Labour MP for Chorley:  \n","Speech transcript: We now come to the SNP spokesperson, Mr MacNeil.  \n","\n","Speaker: Scottish National Party MP for Na h-Eileanan an Iar (additional roles: House Of Commons Shadow SNP Spokesperson (International Development).):  \n","Speech transcript: Thank you, Mr Speaker. I hope you are well. The Minister has talked about the benefits of AI and the Governmentâs desire to make the UK a global leader in the field. Will he therefore commit to ensuring that there is sufficient funding for the development of the UKâs AI sector, so that we can be a global leader?  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: I can confirm to the hon. Gentleman that we have a number of funding programmes in place. The Government have made a number of investments in AI. The AI sector deal was published last year and, in the spring statement, the Chancellor announced an additional Â£150 million for the AI sector.  \n","\n","Speaker: Labour MP for Chorley:  \n","Speech transcript: I call the shadow Minister, Ms Abbott.  \n","\n","Speaker: Labour MP for Hackney North and Stoke Newington:  \n","Speech transcript: Thank you, Mr Speaker. AI can have a huge impact on our economy and on the way we live. We know that it is a key driver of productivity, and we have heard today about its impact on jobs. Does the Minister agree that we need to be very careful about the impact of AI on the economy, and that we should be investing in skills to ensure that people are able to take advantage of the opportunities that AI brings?  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: The hon. Lady is absolutely right. We need to ensure that people have the skills to take advantage of the opportunities that AI brings. The Government have put in place a number of initiatives to help people to develop the skills they need. For example, the National Retraining Scheme is being piloted at the moment, and we are also looking at how we can use AI to help people with their skills development.  \n","\n","Speaker: Conservative MP for South West Hertfordshire:  \n","Speech transcript: I welcome the Governmentâs new AI strategy, and the Ministerâs statement, but I wonder whether he can tell us a little more about how the Government intend to take forward the consultation that is currently under way, and whether we will see a final strategy by the end of the year.  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: My hon. Friend is right to say that the consultation is under way, and we are looking at the responses. I would like to see a final strategy by the end of the year.  \n","\n","Speaker: Labour MP for Walsall South:  \n","Speech transcript: I am sure that the Minister agrees that, as with any new technology, the introduction of AI must be carefully monitored. The Government have made it clear that they want the UK to be a global leader in the development of AI, but will the Minister tell us what steps the Government are taking to ensure that we have the skills, the workforce and the infrastructure in place to make this happen?  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: The Government are taking a number of steps to make sure that we have the skills, workforce and infrastructure in place. As I have said, we are looking at how we can use AI to help people with their skills development. We have put in place the National Retraining Scheme, and we have the T-levels coming in, which will help people to develop the skills they need for the jobs of the future. We are also looking at how we can use AI to help with infrastructure, for example, to help with traffic congestion and to make sure that we have the infrastructure we need to meet the demands of the future.  \n","\n","Speaker: Conservative MP for New Forest West:  \n","Speech transcript: Will the Minister tell us what the Government are doing to ensure that AI is used to prevent crime?  \n","\n","Speaker: Conservative MP for Witney (additional roles: House Of Commons Minister of State (London).):  \n","Speech transcript: The Government are looking at how we can use AI to help with crime prevention. We are working with the Home Office and the police on this. We are looking at how we can use AI to help with crime prevention, and to make sure that the police have the tools they need to tackle crime.  \n","\n","Speaker: Labour MP for Hove:  \n","Speech transcript: What steps he is taking to ensure that the Department for Business, Energy and Industrial Strategy (DBEIS) meets its statutory equality duty.  \n","\n","Speaker: Conservative MP for East Surrey:  \n","Speech transcript: The Department for Business, Energy and Industrial Strategy is committed to delivering its equality duty. We have a comprehensive range of policies and activities to promote equality of opportunity and eliminate unlawful discrimination in the Department and across the wider economy.  \n","\n","Speaker: Labour MP for Hove:  \n","Speech transcript: A report from the Fawcett Society last week showed that 53% of women working in the UK have been sexually harassed at work. This is a shocking figure, but it is not surprising when we consider that, last year, the Equality and Human Rights Commission said that the Government had failed to tackle sexual harassment in the workplace. What steps are the Government taking to ensure that women are protected from sexual harassment at work?  \n","\n","Speaker: Conservative MP for East Surrey:  \n","Speech transcript: The hon. Lady is absolutely right to raise this issue. It is completely unacceptable that anyone should be harassed at work. We have taken a number of steps to tackle sexual harassment in the workplace. We have provided Â£1.8 million to support charities, including the Fawcett Society, to raise awareness of sexual harassment in the workplace. We have also provided Â£3 million to the Equality and Human Rights Commission to support its inquiry into sexual harassment in the workplace.  \n","\n","Speaker: Conservative MP for Wellingborough:  \n","Speech transcript: What steps the Government are taking to improve access to high-quality apprenticeships.  \n","\n","Speaker: Conservative MP for North West Durham:  \n","Speech transcript: What steps the Government are taking to improve access to high-quality apprenticeships.  \n","\n","Speaker: Conservative MP for Reading East (additional roles: House Of Commons The Parliamentary Under-Secretary of State for Education.):  \n","Speech transcript: Apprenticeships are a great way for people to get high-quality skills and to start a rewarding career. We have seen a 67% increase in the number of apprenticeships started in the last 12 months.  \n","\n","Speaker: Conservative MP for Wellingborough:  \n","Speech transcript: I thank my hon. Friend for that answer. I have visited many apprentices in my constituency, including at the Northants-based company Bake-Rite, which provides high-quality apprenticeships in engineering. Does my hon. Friend agree that the Governmentâs apprenticeship reforms are having a positive impact on apprenticeships and that the changes to the levy\n"]}],"source":["def format_output(text):\n","  text = text.replace('\\n', '')\n","  text = text.replace('Speaker:', '\\n\\nSpeaker:')\n","  text = text.replace('Speech transcript:', '\\nSpeech transcript:')\n","  return text\n","\n","# Clean the output format\n","print(format_output(result))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/mistralai/mistral-finetune/blob/main/tutorials/mistral_finetune_7b.ipynb","timestamp":1717429439025}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d4a07c4046984a37ad0d2dbf96daa2bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c7436aa4095415092a325dbbcddc1cd","IPY_MODEL_eb6abfaec718449cae35834940eb6838","IPY_MODEL_841528f7b7474547a1bb9d7cf2a9a411"],"layout":"IPY_MODEL_e8d596ea4f4045f8a74aa68d2a9973c2"}},"8c7436aa4095415092a325dbbcddc1cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1460fdb476ac46169bacfc306807474c","placeholder":"​","style":"IPY_MODEL_29f47329cb8742558b2e24100f2d524d","value":"Fetching 3 files: 100%"}},"eb6abfaec718449cae35834940eb6838":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aad8e74c29c34bfb82145de596c41f60","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_162040ec2fb547498ee7659bc9d7fe59","value":3}},"841528f7b7474547a1bb9d7cf2a9a411":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccd07454030242e5beee6905660b4ecd","placeholder":"​","style":"IPY_MODEL_8847a3b6735f4136a41bb49056e23de8","value":" 3/3 [00:39&lt;00:00, 39.59s/it]"}},"e8d596ea4f4045f8a74aa68d2a9973c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1460fdb476ac46169bacfc306807474c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29f47329cb8742558b2e24100f2d524d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad8e74c29c34bfb82145de596c41f60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"162040ec2fb547498ee7659bc9d7fe59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccd07454030242e5beee6905660b4ecd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8847a3b6735f4136a41bb49056e23de8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8db552559b84c278c794d95830196b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a32bb6ae7504dfbab11fe1ebf3c5f23","IPY_MODEL_fd0711e53c8b4a059e8d20a7b6d234d5","IPY_MODEL_007245925bda47e8b551cb54877417c7"],"layout":"IPY_MODEL_0755f9ea74c64a518598e24e0f61d12d"}},"8a32bb6ae7504dfbab11fe1ebf3c5f23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff754191cd854d7eb733a46733031a47","placeholder":"​","style":"IPY_MODEL_3f3068bc0c3e4c72a003fbfc8ed9fce0","value":"consolidated.safetensors: 100%"}},"fd0711e53c8b4a059e8d20a7b6d234d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a7df27a7e1439c818fcbb285fbf7a6","max":14496078512,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e26bfef91aa40e983564fe2b476cfe4","value":14496078512}},"007245925bda47e8b551cb54877417c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f7bb65c2ebe4aa09905e64134ae0a91","placeholder":"​","style":"IPY_MODEL_e7aeb623a27e42008ea9e7c5a18008af","value":" 14.5G/14.5G [00:39&lt;00:00, 362MB/s]"}},"0755f9ea74c64a518598e24e0f61d12d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff754191cd854d7eb733a46733031a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f3068bc0c3e4c72a003fbfc8ed9fce0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76a7df27a7e1439c818fcbb285fbf7a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e26bfef91aa40e983564fe2b476cfe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f7bb65c2ebe4aa09905e64134ae0a91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7aeb623a27e42008ea9e7c5a18008af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e25537c0f1414a248e2d76601d0eda94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_682b7a35f5f64101ba026a7acc4d9776","IPY_MODEL_2ef605f93e814a9c9988ba2bbb479469","IPY_MODEL_21346a94c4d04a43bd06a945c26e4acb"],"layout":"IPY_MODEL_0464ad18685a4d0194f9a85c9684c4ce"}},"682b7a35f5f64101ba026a7acc4d9776":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b52157bf244674bb18b8e9aeb3a0b6","placeholder":"​","style":"IPY_MODEL_beece1fb0e614e9ab76c90ccb70b0b4e","value":"params.json: 100%"}},"2ef605f93e814a9c9988ba2bbb479469":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_266853e8691249cb95e6b7d66d95602c","max":202,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49060c347b484026901df49c89ed2552","value":202}},"21346a94c4d04a43bd06a945c26e4acb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fed806614e2d421897188405fc694b6f","placeholder":"​","style":"IPY_MODEL_8a7fbc079f7048d48b0fb19908f27c34","value":" 202/202 [00:00&lt;00:00, 14.4kB/s]"}},"0464ad18685a4d0194f9a85c9684c4ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b52157bf244674bb18b8e9aeb3a0b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beece1fb0e614e9ab76c90ccb70b0b4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"266853e8691249cb95e6b7d66d95602c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49060c347b484026901df49c89ed2552":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fed806614e2d421897188405fc694b6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a7fbc079f7048d48b0fb19908f27c34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f568358dde724007b31a3b155d91bcd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62bf269d7bad45e7b494a3b9a4c8486a","IPY_MODEL_88ffad6d80de49b5b1ac7cb8d8b0c14f","IPY_MODEL_438266e9baa9492da155f74c16743f10"],"layout":"IPY_MODEL_e9e15eab077744f2b8b0e65c968f03e6"}},"62bf269d7bad45e7b494a3b9a4c8486a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f344a4d5eb44e3badce32876dd09f96","placeholder":"​","style":"IPY_MODEL_750d75b2fead48d4b7b22dcb5ec76459","value":"tokenizer.model.v3: 100%"}},"88ffad6d80de49b5b1ac7cb8d8b0c14f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c32a9c23f22b4f7a8dfe9b0d7f5cbace","max":587404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c25cc6c8a5943d6ada376052048cbd2","value":587404}},"438266e9baa9492da155f74c16743f10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cbc3ff57a104f75946333630c3cded8","placeholder":"​","style":"IPY_MODEL_45660dbcf0c643fdbfefbcefa024a577","value":" 587k/587k [00:00&lt;00:00, 22.0MB/s]"}},"e9e15eab077744f2b8b0e65c968f03e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f344a4d5eb44e3badce32876dd09f96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"750d75b2fead48d4b7b22dcb5ec76459":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c32a9c23f22b4f7a8dfe9b0d7f5cbace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c25cc6c8a5943d6ada376052048cbd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cbc3ff57a104f75946333630c3cded8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45660dbcf0c643fdbfefbcefa024a577":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ed214fc4c54210b19e48c3fbb2e579":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ddea8d0c7de4d31a75544bb471cf0f1","IPY_MODEL_3f1cc5700ae24d09bf64c05cadaf97ce","IPY_MODEL_f097ca78ee3242ce923526e8ff5561ba"],"layout":"IPY_MODEL_8cb69d9737fc41958aa884e08d12efb3"}},"0ddea8d0c7de4d31a75544bb471cf0f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44dcbe360e9f451e9c2a0ca6df27cd56","placeholder":"​","style":"IPY_MODEL_01e50de05da045b6b93b2f94e1d4eaae","value":""}},"3f1cc5700ae24d09bf64c05cadaf97ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0be7c5f404ef40c996b50f23c084f5c5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3a3ad34a6b24c26b208356c49d04b7c","value":0}},"f097ca78ee3242ce923526e8ff5561ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46c2c4f38ffa4a07a791250c234396da","placeholder":"​","style":"IPY_MODEL_f51890b1a60142279c6c055fadb5f698","value":" 0/0 [00:00&lt;?, ?it/s]"}},"8cb69d9737fc41958aa884e08d12efb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44dcbe360e9f451e9c2a0ca6df27cd56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e50de05da045b6b93b2f94e1d4eaae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0be7c5f404ef40c996b50f23c084f5c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d3a3ad34a6b24c26b208356c49d04b7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46c2c4f38ffa4a07a791250c234396da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51890b1a60142279c6c055fadb5f698":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}